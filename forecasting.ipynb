{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting\n",
    "\n",
    "This notebook shows how to implement sequence models in tensorflow. Mainly, it uses recurrent neural network to do forecasting. The example below is based on climate chage data. Give time series temperatures, we will try to find patterns and predict how hot will it be in the upcoming months.\n",
    "\n",
    "As for the machine learning, the following concepts are covered:\n",
    "\n",
    "- Data prerocessing\n",
    "    - data normalization\n",
    "    - train/test split\n",
    "    - creating windows\n",
    "    - creating labels\n",
    "    - preventing sequence bias\n",
    "- Neural Networks\n",
    "    - convolutional layers\n",
    "    - LSTM layers\n",
    "    - fully-connected layers\n",
    "    - optimal choice of learning rate\n",
    "- Callbacks\n",
    "- Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The notebook is based on Climate Change dataset from Berkely Earth. It contains earth surface temperature for multiple cities in the world. You will hence be able to develop the model for a city of your choice!\n",
    "The time series start in 1750 and has one observation per month.\n",
    "\n",
    "To start, [download the data](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data/download) and place it in your working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import (find_year_index, forecast_timeseries, preprocess_timeseries,\n",
    "                   unpack_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: \n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"climate-change-earth-surface-temperature-data.zip\"\n",
    "DATA_DIR = \"climate\"\n",
    "\n",
    "unpack_file(DATA_FILE, DATA_DIR)\n",
    "\n",
    "DATA_FILE = DATA_DIR + \"/GlobalLandTemperaturesByCity.csv\"\n",
    "CITY = \"Zurich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading \n",
    "dates = []\n",
    "temperatures = []\n",
    "\n",
    "date_index = 0\n",
    "temp_index = 1\n",
    "city_index = 3\n",
    "\n",
    "with open(DATA_FILE, \"r\") as file:\n",
    "\n",
    "    reader = csv.reader(file, delimiter=\",\")\n",
    "    next(reader)\n",
    "    \n",
    "    for row in reader:\n",
    "        if row[city_index] == CITY:\n",
    "            dates.append(row[date_index])\n",
    "            temperatures.append(row[temp_index])\n",
    "            \n",
    "dates = [datetime.date.fromisoformat(date) for date in dates]\n",
    "temperatures = [float(temp) if temp != \"\" else None for temp in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what was the temperature in the past years. \n",
    "start, stop = find_year_index(dates, 1900)\n",
    "\n",
    "plt.figure(figsize=(22,6))\n",
    "plt.plot(dates[start:stop],temperatures[start:stop])\n",
    "plt.title('Temperature variation in {}'.format(CITY))\n",
    "plt.ylabel(\"Temperature [C]\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have some missing values at the beginning of our series. Let's find out where they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_none = [i for i, temp in enumerate(temperatures) if temp == None]\n",
    "print(\"There are missing values at indices: {}\".format(where_none))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that they appear at the beginning only, let's just cut them off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperatures = temperatures[107:-1]\n",
    "dates = dates[107:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's normalize the data. We will split the data at SPLIT_TIME for train and test set.\n",
    "# The normalization is based moments from test set only (!).\n",
    "\n",
    "SPLIT_TIME = 2775\n",
    "\n",
    "train_data = temperatures[:SPLIT_TIME]\n",
    "train_mean = sum(train_data)/len(train_data)\n",
    "squared_diff = [(x - train_mean)**2 for x in train_data]\n",
    "train_std = sum(squared_diff)/(len(train_data)-1)\n",
    "\n",
    "normalized_data = [(x-train_mean)/train_std for x in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to preprocess the data. We will use rolling window to create input sequence and labels.\n",
    "\n",
    "WINDOW_SIZE = 24\n",
    "BATCH_SIZE = 2\n",
    "SHUFFLE_BUFFER = 50\n",
    "\n",
    "input_data = preprocess_timeseries(normalized_data[:SPLIT_TIME], WINDOW_SIZE, BATCH_SIZE, SHUFFLE_BUFFER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "Let's build a recurrent neural network.  We will formulate this probelm as multiclass classification. As the input, we will use a sequences of temperatures. As the output, we will use the last measurement in this sequence. Neural network will then learn trend and seasonality patterns. As a result, we will be able to forecast tomorrow's temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size = 5, padding=\"causal\", activation=\"relu\", input_shape=[None,1]),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dense(30, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we will define learning rate scheduler. It will automatically try out different learning rates for us. \n",
    "We will then be able to compare them, and choose the optimal. Now training longer is much more meaningful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to train our model. \n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-6 * 10**(epoch / 4))\n",
    "\n",
    "model.compile(optimizer=\"adam\", \n",
    "              metrics=[\"mae\"], \n",
    "              loss=tf.keras.losses.Huber())\n",
    "\n",
    "history = model.fit(input_data, \n",
    "                    epochs=15, \n",
    "                    callbacks = [lr_schedule])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find optimal learning rate\n",
    "\n",
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.ylabel(\"Log loss\")\n",
    "plt.xlabel(\"Learning rate\")\n",
    "\n",
    "plt.axis([1e-6, 1.5e-4, -0.01, 0.02])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training with optimal learning rate\n",
    "\n",
    "OPTIMAL_LR = 1e-5\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=OPTIMAL_LR), \n",
    "              metrics=[\"mae\"], \n",
    "              loss=tf.keras.losses.Huber())\n",
    "\n",
    "history = model.fit(input_data, \n",
    "                    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate model performance on test data.\n",
    "\n",
    "forecast = forecast_timeseries(model, normalized_data, WINDOW_SIZE)\n",
    "forecast = forecast[SPLIT_TIME - WINDOW_SIZE:-1, -1, 0]\n",
    "\n",
    "mae = tf.keras.metrics.mean_absolute_error(forecast, normalized_data[SPLIT_TIME:]).numpy()\n",
    "mse = tf.keras.metrics.mean_squared_error(forecast, normalized_data[SPLIT_TIME:]).numpy()\n",
    "\n",
    "print(\"Mean absolute error: {}\".format(mae))\n",
    "print(\"Mean squared error: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does our forecast compare to realized values?\n",
    "\n",
    "renormalized_forecast = [f*train_std + train_mean for f in forecast]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(dates[SPLIT_TIME:], temperatures[SPLIT_TIME:])\n",
    "plt.plot(dates[SPLIT_TIME:], renormalized_forecast)\n",
    "plt.ylabel(\"Temperature\")\n",
    "plt.legend([\"Actual\", \"Forecast\"])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_goggles",
   "language": "python",
   "name": "solid_goggles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
