{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification\n",
    "\n",
    "This notebook shows how to implement image classification in tensorflow. It's based on images of natural scenes around the world. \n",
    "It will allow you to classify buildings, forests, glaciers, mountains, sea and street scenery.\n",
    "\n",
    "As for the machine learning, the following concepts are covered:\n",
    "\n",
    "- Data generators:\n",
    "    - image scaling\n",
    "    - labels encoding\n",
    "    - batch loading\n",
    "- Data augmentation\n",
    "- Convolutional Neural Networks\n",
    "    - convolutional layers\n",
    "    - pooling layers\n",
    "    - fully-connected layers\n",
    "    - dropout\n",
    "- Callbacks\n",
    "- Transfer learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The notebook is based on Intel Image Classification dataset. It contains 25k images of various landscapes. After building (and training) the neural network, you will be able to classify any landscape image as belonging to one of those categories:\n",
    "- buildings\n",
    "- forest\n",
    "- glacier\n",
    "- mountain\n",
    "- sea\n",
    "- street\n",
    "\n",
    "To start, [download the data](https://www.kaggle.com/puneet6060/intel-image-classification/download) and place it in your working directory. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import (AccuracyCallback, pick_files_from_directory, plot_training_progress,\n",
    "                   plot_sample_images, unpack_file, visualize_convolutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure GPU\n",
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "for device in gpu_devices: \n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"intel-image-classification.zip\"\n",
    "DATA_DIR = \"data/images\"\n",
    "\n",
    "unpack_file(DATA_FILE, DATA_DIR)\n",
    "\n",
    "TRAIN_DIR = DATA_DIR + \"/seg_train/seg_train\"\n",
    "TEST_DIR = DATA_DIR + \"/seg_test/seg_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot sample images\n",
    "\n",
    "categories = os.listdir(TRAIN_DIR)\n",
    "print(\"Categories are: {}\".format(', '.join(categories)))\n",
    "\n",
    "%matplotlib inline\n",
    "plot_sample_images(TRAIN_DIR, categories, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process input data. Include data augmentation.\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                  rotation_range=40,\n",
    "                                                                  width_shift_range=0.2,\n",
    "                                                                  height_shift_range=0.2,\n",
    "                                                                  shear_range=0.2,\n",
    "                                                                  zoom_range=0.2,\n",
    "                                                                  horizontal_flip=True,\n",
    "                                                                  fill_mode='nearest')\n",
    "\n",
    "train_generator = image_generator.flow_from_directory(\n",
    "    TRAIN_DIR, target_size=(150, 150), class_mode=\"categorical\", batch_size=32)\n",
    "\n",
    "test_generator = image_generator.flow_from_directory(\n",
    "    TEST_DIR, target_size=(150, 150), class_mode=\"categorical\", batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "Let's build a simple conv net for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "\n",
    "vanilla_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(vanilla_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's time to train our model. \n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "accuracy_callback = AccuracyCallback(0.9)\n",
    "\n",
    "vanilla_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001),\n",
    "                      loss=\"categorical_crossentropy\",\n",
    "                      metrics=[\"acc\"])\n",
    "\n",
    "history_vanilla = vanilla_model.fit(train_generator,\n",
    "                                    validation_data=test_generator,\n",
    "                                    epochs=2,\n",
    "                                    verbose=1,\n",
    "                                    callbacks=[accuracy_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate its performance on test data\n",
    "\n",
    "test_metrics = vanilla_model.evaluate(test_generator)\n",
    "\n",
    "for i in range(len(test_metrics)):\n",
    "    print(\"Test {}: {}\".format(vanilla_model.metrics_names[i], test_metrics[i]))\n",
    "    \n",
    "plot_training_progress(history_vanilla, \"acc\")\n",
    "plot_training_progress(history_vanilla, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have evaluated models by accuracy and log loss. Now, let's see how our model performs on random pictures. \n",
    "\n",
    "Can it correctly regognize the landscape images of your choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of images you would like to classify (full path).\n",
    "\n",
    "files = []\n",
    "for category in categories:\n",
    "    files += pick_files_from_directory(os.path.join(TEST_DIR, category), k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's classify those images \n",
    "\n",
    "inputs = []\n",
    "for file in files: \n",
    "    img = tf.keras.preprocessing.image.load_img(file, target_size=(150, 150, 3))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    inputs.append(np.expand_dims(x, axis=0))\n",
    "\n",
    "images = np.vstack(inputs)\n",
    "labels = vanilla_model.predict_classes(images)\n",
    "\n",
    "id_to_class = {value: key for key, value in train_generator.class_indices.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plottng results. How may did you get wrong?\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 50)\n",
    "\n",
    "i = 0\n",
    "for file, label in zip(files, labels):\n",
    "    \n",
    "    sp = plt.subplot(int(len(files)/2), 2, i+1)\n",
    "    sp.axis(\"Off\")\n",
    "    \n",
    "    img = mpimg.imread(file)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.title(\"Predicted: {}\".format(id_to_class[label]))\n",
    "    i+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Can we do any better than that? \n",
    "\n",
    "Instead of training our model for long hours, let us build upon well-trained models. \n",
    "We will use InceptionV3 model traned on ImageNet. We will modify a couple of last layers to allow the network to learn features specific to out landscape dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's implement transfer learning\n",
    "\n",
    "pretrained_model = tf.keras.applications.InceptionV3(input_shape=(150, 150, 3),\n",
    "                                                      include_top=False,\n",
    "                                                      weights='imagenet')\n",
    "\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "last_layer = pretrained_model.get_layer(\"mixed8\")\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "tl_model = tf.keras.models.Model(pretrained_model.input, x)\n",
    "\n",
    "tl_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
    "                 loss=\"categorical_crossentropy\",\n",
    "                 metrics=[\"acc\"])\n",
    "\n",
    "print(tl_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to train model based on transfer learning. \n",
    "tf.keras.backend.clear_session()\n",
    "            \n",
    "tl_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), \n",
    "                 loss=\"categorical_crossentropy\", \n",
    "                 metrics=[\"acc\"])\n",
    "\n",
    "history_tl = tl_model.fit(train_generator, \n",
    "                          validation_data=test_generator, \n",
    "                          epochs=1, \n",
    "                          verbose=1, \n",
    "                          callbacks=[accuracy_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate its performance on test data. Does it do any better than the model we built from scratch?\n",
    "\n",
    "test_metrics = tl_model.evaluate(test_generator)\n",
    "\n",
    "for i in range(len(test_metrics)):\n",
    "    print(\"Test {}: {}\".format(vanilla_model.metrics_names[i], test_metrics[i]))\n",
    "    \n",
    "plot_training_progress(history_tl, \"acc\")\n",
    "plot_training_progress(history_tl, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing convolutions\n",
    "\n",
    "We have seen how to build and train image classification model. The core part of this model, are convolutions and pooling layers. Let's have a look at what do they actually do. \n",
    "\n",
    "Who does an image look like after passing through each Conv2D and MaxPooling layer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convolutions\n",
    "category = \"forest\"\n",
    "model = vanilla_model\n",
    "img = pick_files_from_directory(os.path.join(TRAIN_DIR, category))[0]\n",
    "\n",
    "visualize_convolutions(model, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_goggles",
   "language": "python",
   "name": "solid_goggles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
