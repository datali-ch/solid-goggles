{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from snippets import unpack_file, MyCallback, plot_graphs, visualize_convolutions, pick_files_from_directory\n",
    "import random\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"intel-image-classification.zip\"\n",
    "DIR = \"images\"\n",
    "\n",
    "unpack_file(DATA_FILE, DIR)\n",
    "\n",
    "TRAIN_DIR = \"images/seg_train/seg_train\"\n",
    "TEST_DIR = \"images/seg_test/seg_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample images\n",
    "\n",
    "%matplotlib inline\n",
    "categories = os.listdir(TRAIN_DIR)\n",
    "\n",
    "IMG_PER_ROW = 4\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(IMG_PER_ROW*4, len(categories)*4)\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    \n",
    "    curr_path = os.path.join(TRAIN_DIR, category)\n",
    "    path_to_images = pick_files_from_directory(curr_path, k=IMG_PER_ROW)\n",
    "    \n",
    "    for j, image_path in enumerate(path_to_images):\n",
    "        \n",
    "        sp = plt.subplot(len(categories), IMG_PER_ROW, i*IMG_PER_ROW + j + 1)\n",
    "        sp.axis(\"Off\")\n",
    "        \n",
    "        img = mpimg.imread(image_path)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process input data\n",
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                  rotation_range=40,\n",
    "                                                                  width_shift_range=0.2,\n",
    "                                                                  height_shift_range=0.2,\n",
    "                                                                  shear_range=0.2,\n",
    "                                                                  zoom_range=0.2,\n",
    "                                                                  horizontal_flip=True,\n",
    "                                                                  fill_mode='nearest')\n",
    "\n",
    "train_generator = image_generator.flow_from_directory(TRAIN_DIR, target_size=(150, 150), class_mode=\"categorical\", batch_size=32)\n",
    "test_generator = image_generator.flow_from_directory(TEST_DIR, target_size=(150, 150), class_mode=\"categorical\", batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN from scratch\n",
    "vanilla_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation=\"relu\", input_shape=(150,150,3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(6, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "print(vanilla_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "            \n",
    "my_callback = MyCallback(0.7)\n",
    "vanilla_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history_vanilla = vanilla_model.fit(train_generator, validation_data=test_generator, epochs=5, verbose=1, callbacks=[my_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = vanilla_model.evaluate_generator(test_generator)\n",
    "\n",
    "for i in range(len(test_metrics)):\n",
    "    print(\"Test {}: {}\".format(vanilla_model.metrics_names[i], test_metrics[i]))\n",
    "    \n",
    "plot_graphs(history_vanilla, \"acc\")\n",
    "plot_graphs(history_vanilla, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN with transfer learning\n",
    "pre_trained_model = tf.keras.applications.InceptionV3(input_shape=(150,150,3), \n",
    "                                                      include_top=False, \n",
    "                                                      weights='imagenet')\n",
    "\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "    \n",
    "last_layer = pre_trained_model.get_layer(\"mixed8\")\n",
    "last_output = last_layer.output\n",
    "\n",
    "x = tf.keras.layers.Flatten()(last_output)\n",
    "x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)                  \n",
    "x = tf.keras.layers.Dense(6, activation=\"softmax\")(x)           \n",
    "\n",
    "tl_model = tf.keras.models.Model(pre_trained_model.input, x)\n",
    "\n",
    "tl_model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0.0001), \n",
    "              loss = \"categorical_crossentropy\", \n",
    "              metrics = [\"acc\"])\n",
    "\n",
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "            \n",
    "tl_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "history_tl = tl_model.fit(train_generator, validation_data=test_generator, epochs=5, verbose=1, callbacks=[my_callback])\n",
    "tl_model(testing_images, testing_labels, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = tl_model.evaluate_generator(test_generator)\n",
    "\n",
    "for i in range(len(test_metrics)):\n",
    "    print(\"Test {}: {}\".format(vanilla_model.metrics_names[i], test_metrics[i]))\n",
    "    \n",
    "plot_graphs(history_tl, \"acc\")\n",
    "plot_graphs(history_tl, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convolutions\n",
    "category = \"buildings\"\n",
    "model = model_vanilla\n",
    "img = pick_files_from_directory(os.path.join(TRAIN_DIR, category))[0]\n",
    "\n",
    "visualize_convolutions(model, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict a file label\n",
    "id_to_class = {value: key for key, value in train_generator.class_indices.items()}\n",
    "\n",
    "files = pick_files_from_directory(os.path.join(TEST_DIR, category), k=10)\n",
    "\n",
    "inputs = []\n",
    "for file in files: \n",
    "    img = tf.keras.preprocessing.image.load_img(file, target_size=(150, 150, 3))\n",
    "    x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    inputs.append(np.expand_dims(x, axis=0))\n",
    "\n",
    "images = np.vstack(inputs)\n",
    "labels = vanilla_model.predict_classes(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot it!\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(15, 50)\n",
    "\n",
    "i = 0\n",
    "for file, label in zip(files, labels):\n",
    "    \n",
    "    sp = plt.subplot(int(len(files)/2), 2, i+1)\n",
    "    sp.axis(\"Off\")\n",
    "    \n",
    "    img = mpimg.imread(file)\n",
    "    plt.imshow(img)\n",
    "    \n",
    "    plt.title(\"Predicted: {}\".format(id_to_class[label]))\n",
    "    i+=1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solid_goggles",
   "language": "python",
   "name": "solid_goggles"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
